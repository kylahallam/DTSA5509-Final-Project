{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-07T21:17:43.779445Z","iopub.execute_input":"2022-08-07T21:17:43.780576Z","iopub.status.idle":"2022-08-07T21:17:43.818325Z","shell.execute_reply.started":"2022-08-07T21:17:43.780432Z","shell.execute_reply":"2022-08-07T21:17:43.817335Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# **Notebook Outline:**\n#### 1. Project Topic\n#### 2. Data Overview\n#### 3. Data Cleaning\n#### 4. Exploratory Data Analysis\n#### 5. Models: Build, Results, Analysis\n#### 6. Discussion\n#### 7. Sources","metadata":{}},{"cell_type":"markdown","source":"# **Project Topic:** \n## **Title**: \nPredicting Chronic Kidney Disease Using Supervised Machine Learning Classification Techniques \n## **Overview**: \nFor this project, I will use Logistic Regression, Decision Tree Classifier, and a Random Forest Classifier to perform binary classification for predicting chronic kidney disease and compare the performance of the different models.\n## **Motivation:**\nThis project has important health impacts for the future diagnosis and treatment of Chronic Kidney Disease (CKD). The kidneys' role in the human body is to fiter waste products and prevent waste accumulation in the system. Chronic Kidney Disease is when a kidney can no longer filter the waste as expected. In the United States alone, 37 million people (or 15% of the population) is estimated to have CKD (https://www.cdc.gov/kidneydisease/publications-resources/ckd-national-facts.html). Furthermore, as many as 9 in every 10 adults with Chronic Kidney Disease (CKD) do not know that they have CKD (https://www.cdc.gov/kidneydisease/publications-resources/ckd-national-facts.html). For these reasons, with CKD being a relatively common health issue and with many sufferers being unaware of the illness, it is important to have methods to diagnose instances of CKD in new patients. By training models to recognize instances of the disease we offer a simple way for future individuals to be diagnosed. \nOn a personal level, this project is very important to me since I was diagnosed with CKD at the age of 16 after falling ill unexpectedly. Until I arrived at the hospital I was unaware that I had CKD. I chose this project so that I can personally better understand predictors of the illness as well as work on a topic that impacts a large number of other individuals. ","metadata":{}},{"cell_type":"markdown","source":"# **Data Set Description**\n## **Source**:\nThis dataset is originally from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/chronic_kidney_disease). \n    \n>     Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of\n    Information and Computer Science.\n    \nI am using the dataset uploaded on kaggle here:\n>     Iqbal, M. (2017, April 13). Chronic kidney disease dataset. Kaggle. Retrieved August 6, 2022, from https://www.kaggle.com/datasets/mansoordaku/ckdisease\n\n## **Data Description**\nThe dataset contains information collected on individuals who presented at a hospital in India over a 2 month period. The data set has 400 instances, 25 attributes, and contains missing values. The following features compose the dataset (from the data description of the data set on the UCI webpage (https://archive.ics.uci.edu/ml/datasets/chronic_kidney_disease#)):\n* age - Age\n* bp - Blood Pressure\n* sg - Specific Gravity\n* al - Albumin\n* su - Sugar\n* rbc - Red Blood Cells\n* pc -  pus cell\n* pcc - pus cell clumps\n* ba - bacteria\n* bgr - blood glucose random\n* bu - blood urea\n* sc - serum creatinine\n* sod - sodium\n* pot - potassium\n* hemo - hemoglobin\n* pcv - packed cell volume \n* wc - white blood cell count \n* rc - red blood cell count\n* htn - hypertension\n* dm - diabetes mellitus\n* cad - coronary artery disease\n* pe - pedal edema\n* ane -anemia\n* classification - class\n\nThe \"classification\" is the target variable indicating whether the individual has CKD or does not have CKD, hence why the data set is well suited for a binary class classification model","metadata":{}},{"cell_type":"code","source":"# Importing all key libraries to complete the project\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport math\nimport seaborn as sns\nfrom sklearn.utils import resample\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tools.tools import add_constant\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\nimport missingno as msno\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:44.009000Z","iopub.execute_input":"2022-08-07T21:17:44.009597Z","iopub.status.idle":"2022-08-07T21:17:45.888897Z","shell.execute_reply.started":"2022-08-07T21:17:44.009563Z","shell.execute_reply":"2022-08-07T21:17:45.887735Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **Data Set Overview**\nIn this section, the data set will be examined. First, a high level overview of the data will be presented before delving further into the data to ensure that each observation is correctly considered.","metadata":{}},{"cell_type":"code","source":"ckd_data = pd.read_csv('/kaggle/input/ckdisease/kidney_disease.csv') #importing .csv file\nckd_data.info() #print a summary of the data set we will use in this project","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:45.892462Z","iopub.execute_input":"2022-08-07T21:17:45.893188Z","iopub.status.idle":"2022-08-07T21:17:45.938035Z","shell.execute_reply.started":"2022-08-07T21:17:45.893142Z","shell.execute_reply":"2022-08-07T21:17:45.937169Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"* There are 400 total observations and 25 feature columns and 1 target column\n* The informational summary displays the null count of the data set. It is evident that there are several instances of missing data that will need to be cleaned later. \n* **Classification** is our target variable and describes whether this entry is classified as having CKD or not having CKD. ","metadata":{}},{"cell_type":"code","source":"ckd_data.head() # examine the first 5 entries of the data.","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:45.939210Z","iopub.execute_input":"2022-08-07T21:17:45.939713Z","iopub.status.idle":"2022-08-07T21:17:45.974121Z","shell.execute_reply.started":"2022-08-07T21:17:45.939663Z","shell.execute_reply":"2022-08-07T21:17:45.973226Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Within the dataset, there are both numerical and categorical entries. There are 11 numeric and 14 categorical feature types as well as a binary class target variable","metadata":{}},{"cell_type":"markdown","source":"# **Data Cleaning**","metadata":{}},{"cell_type":"markdown","source":"#### Overview: In this section, the data set will be prepared for use in the machine learning model. This requires several tasks:\n1. Remove extraneous features\n2. Check for a balanced data set\n3. Examine data set for missing values \n    * Decide whether data set is eligible for Complete Case Analysis (CCA)\n    * Remove features with too many NaNs\n    * Impute any features with NaNs below a defined threshold\n    \n\n4. Any other data cleaning techniques that are appropriate for this particular data set. ","metadata":{}},{"cell_type":"markdown","source":"## 1.  Remove Extraneous Features\nID is a redundant feature that needs to be removed, as it is a number assigned to the patient entry and is not used in prediction.","metadata":{}},{"cell_type":"code","source":"ckd_data.drop('id', axis = 1, inplace = True) # drop the ID column\nckd_data.info() #show that the id column has been dropped","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:45.976187Z","iopub.execute_input":"2022-08-07T21:17:45.976707Z","iopub.status.idle":"2022-08-07T21:17:45.993565Z","shell.execute_reply.started":"2022-08-07T21:17:45.976656Z","shell.execute_reply":"2022-08-07T21:17:45.992797Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## 2. Check For Balanced Data Set\nFirst, list the classes for the target variable:","metadata":{}},{"cell_type":"code","source":"ckd_data.classification.unique() #Taking a closer look at what the Classification instances look like","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:45.995103Z","iopub.execute_input":"2022-08-07T21:17:45.995701Z","iopub.status.idle":"2022-08-07T21:17:46.002439Z","shell.execute_reply.started":"2022-08-07T21:17:45.995651Z","shell.execute_reply":"2022-08-07T21:17:46.001365Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Based on the examination above, there is a typo in the dataset, incorrectly coding \"ckd\" as both \"ckd\" and \"ckd\\t.\" This needs to be fixed before the data set can be checked for class imbalance.","metadata":{}},{"cell_type":"code","source":"ckd_data.classification = ckd_data.classification.replace('ckd\\t', 'ckd') #here we replace every instance of ckd\\t with ckd\nckd_data.classification.unique() #verify that replacement was successful","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:46.004001Z","iopub.execute_input":"2022-08-07T21:17:46.004563Z","iopub.status.idle":"2022-08-07T21:17:46.014771Z","shell.execute_reply.started":"2022-08-07T21:17:46.004532Z","shell.execute_reply":"2022-08-07T21:17:46.013628Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"We will now determine if the data set is balanced or unbalanced by comparing the number of observations with \"CKD\" vs number of observations with \"Not CKD\"","metadata":{}},{"cell_type":"code","source":"classification_counts = ckd_data['classification'].value_counts() #count how many instances of CKD vs not CKD\nplt.figure()\nclassification_counts.plot(kind='bar', title = 'Count of CKD vs Not CKD') #bar plot of these instances ","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:46.016563Z","iopub.execute_input":"2022-08-07T21:17:46.017862Z","iopub.status.idle":"2022-08-07T21:17:46.243743Z","shell.execute_reply.started":"2022-08-07T21:17:46.017804Z","shell.execute_reply":"2022-08-07T21:17:46.242455Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"The above plot demonstrates that the data set is imbalanced, with more instances of CKD in the dataset than instances of NOT CKD. To solve this issue, we can **oversample** the minority class, in this case the NOT CKD instances (Brownlee). The imbalanced data set will be addressed in the model build section of the project.","metadata":{}},{"cell_type":"markdown","source":"CKD and NOT CKD will now be encoded as 1 and 0 respectively for future use in the Machine Learning Models.","metadata":{}},{"cell_type":"code","source":"ckd_data['classification'].replace({'ckd':1, 'notckd':0}, inplace = True) # Since this is a binary class classification, we will encode CKD class as a \"1\" and Not CKD as \"0\"\nckd_data.classification.unique() #verify success of replacement","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:46.245365Z","iopub.execute_input":"2022-08-07T21:17:46.245703Z","iopub.status.idle":"2022-08-07T21:17:46.257413Z","shell.execute_reply.started":"2022-08-07T21:17:46.245650Z","shell.execute_reply":"2022-08-07T21:17:46.256102Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## 3. Handle missing values in the data set\n#### In this section, entries with missing values will be examined. The features with many missing values will either be imputed or dropped.","metadata":{}},{"cell_type":"code","source":"nulls = ckd_data.isnull().sum() #Count how many nulls there are in the each feature","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:46.259223Z","iopub.execute_input":"2022-08-07T21:17:46.260023Z","iopub.status.idle":"2022-08-07T21:17:46.269181Z","shell.execute_reply.started":"2022-08-07T21:17:46.259961Z","shell.execute_reply":"2022-08-07T21:17:46.267657Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"percent_nulls = nulls / ckd_data.shape[0] * 100 # Determine the percent of each feature with nulls\nprint(percent_nulls)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T22:25:46.831252Z","iopub.execute_input":"2022-08-07T22:25:46.831701Z","iopub.status.idle":"2022-08-07T22:25:46.842488Z","shell.execute_reply.started":"2022-08-07T22:25:46.831648Z","shell.execute_reply":"2022-08-07T22:25:46.841119Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"msno.bar(ckd_data) #bar plot to demonstrate the missing values (out of the 400 total observations)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:46.286727Z","iopub.execute_input":"2022-08-07T21:17:46.287165Z","iopub.status.idle":"2022-08-07T21:17:48.136180Z","shell.execute_reply.started":"2022-08-07T21:17:46.287132Z","shell.execute_reply":"2022-08-07T21:17:48.134836Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"If there had been no nulls, each bar plot entry above would have a value of 400. However, as seen above, there are numerous nulls that will need to be dealt with.","metadata":{}},{"cell_type":"code","source":"nulls = ckd_data.isnull().sum(axis=0) #count the number of nulls so that a histogram can be plotted\nnull_counts = nulls[nulls>0] #only plot the existing nulls \n\nbin_width = 5\nhistogram = plt.hist(null_counts, bins = np.arange(0, 140, bin_width))\nplt.title('Histogram: Null Counts')\nplt.ylabel('Number of Features')\nplt.xlabel('Null Count')","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:48.138300Z","iopub.execute_input":"2022-08-07T21:17:48.139270Z","iopub.status.idle":"2022-08-07T21:17:48.402949Z","shell.execute_reply.started":"2022-08-07T21:17:48.139217Z","shell.execute_reply":"2022-08-07T21:17:48.401619Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"* #### The data set is not suitable for Complete Case Analysis (CCA) since there are more than 5% of the total observations that have null values. The next step is to examine each feature and determine which to impute and which to drop. CCA was introduced in Programming Assignment I of this course.\n\n* #### Any feature with more than 15% of the observations with missing values will be removed, the rest will be imputed. This is because we do not want to remove all of our features (thus losing possible influencers on our prediction, but it is not reasonable to impute above a certain threshold given that additional bias will be introduced) Selecting 15% as the threshold keeps as many features as possible (to account for their influence in the model) while also removing those that have a number of nulls that if imputed would bias the model.","metadata":{}},{"cell_type":"markdown","source":"Next, determine which features fall into the category of imputation versus those that need to be removed from the dataset:","metadata":{}},{"cell_type":"code","source":"# this will calc which features have nulls (ie need to be cleaned) but have less than 15% of observations missing\nfeatures_to_impute = ckd_data.columns[(ckd_data.isnull().sum()/len(ckd_data)<0.15)] & ckd_data.columns[(ckd_data.isnull().sum()/len(ckd_data)>0)] \n# this will calc which features have more than 105 of observations missing and need to be thrown away\nfeatures_to_throw = ckd_data.columns[(ckd_data.isnull().sum()/len(ckd_data))>=0.15] \n\nprint(len(features_to_impute), features_to_impute)\nprint(len(features_to_throw), features_to_throw)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:48.404851Z","iopub.execute_input":"2022-08-07T21:17:48.405176Z","iopub.status.idle":"2022-08-07T21:17:48.422750Z","shell.execute_reply.started":"2022-08-07T21:17:48.405146Z","shell.execute_reply":"2022-08-07T21:17:48.421931Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Based on the information above, 17 features will need to be imputed (treated to replace the missing values) and 7 features will need to be removed.\n\nNow, use the \"features to throw\" above to get rid of any features with too many missing values:","metadata":{}},{"cell_type":"code","source":"clean_ckd = ckd_data.drop(features_to_throw, axis=1) #remove the \"features to throw\", ie those with more than 15% of entries missing\nclean_ckd.info() #print out new data frame summary with the removed features","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:48.423787Z","iopub.execute_input":"2022-08-07T21:17:48.424128Z","iopub.status.idle":"2022-08-07T21:17:48.440298Z","shell.execute_reply.started":"2022-08-07T21:17:48.424075Z","shell.execute_reply":"2022-08-07T21:17:48.439407Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Now that the features with too many missing values have been removed, it is time to clean the data further by imputing the missing values in the \"features to impute\" list. The method of imputation will depend on the type of data. A categorical data type will be replaced with the most commonly occuring entry, while a numerical data type null will be replaced with the mode. ","metadata":{}},{"cell_type":"code","source":"for columns in clean_ckd.columns:\n    print(columns, (clean_ckd[columns].unique()), clean_ckd[columns].dtype) #examining the unique values within the dataset before continuing","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:48.441872Z","iopub.execute_input":"2022-08-07T21:17:48.442237Z","iopub.status.idle":"2022-08-07T21:17:48.463088Z","shell.execute_reply.started":"2022-08-07T21:17:48.442206Z","shell.execute_reply":"2022-08-07T21:17:48.461493Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"As is evident, some of the features have some typos and will need to be cleaned before continuing with imputation.","metadata":{}},{"cell_type":"code","source":"# Replace DM errors \nclean_ckd.dm = clean_ckd.dm.replace(' yes', 'yes') #here we replace every instance of yes with an extra space with yes\nclean_ckd.dm = clean_ckd.dm.replace('\\tyes', 'yes') # fixing another error\nclean_ckd.dm = clean_ckd.dm.replace('\\tno', 'no')\nprint('dm',clean_ckd.dm.unique()) #verify that replacement was successful\n\n#Replace CAD errors\nclean_ckd.cad = clean_ckd.cad.replace('\\tno', 'no')\nprint('cad', clean_ckd.dm.unique())","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:48.465285Z","iopub.execute_input":"2022-08-07T21:17:48.465845Z","iopub.status.idle":"2022-08-07T21:17:48.480473Z","shell.execute_reply.started":"2022-08-07T21:17:48.465796Z","shell.execute_reply":"2022-08-07T21:17:48.479205Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Now that we have replaced the typos, we will encode each categorical variable with a binary 0/1 (as we did with the classification target variable) for ease of data analysis","metadata":{}},{"cell_type":"code","source":"clean_ckd['htn'].replace({'yes':1, 'no':0}, inplace = True)\nclean_ckd['dm'].replace({'yes':1, 'no':0}, inplace = True)\nclean_ckd['cad'].replace({'yes':1, 'no':0}, inplace = True)\nclean_ckd['appet'].replace({'good':1, 'poor':0}, inplace = True)\nclean_ckd['ane'].replace({'yes':1, 'no':0}, inplace = True)\nclean_ckd['pe'].replace({'yes':1, 'no':0}, inplace = True)\nclean_ckd['ba'].replace({'present':1, 'notpresent':0}, inplace = True)\nclean_ckd['pcc'].replace({'present':1, 'notpresent':0}, inplace = True)\nclean_ckd.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:48.482600Z","iopub.execute_input":"2022-08-07T21:17:48.482975Z","iopub.status.idle":"2022-08-07T21:17:48.512146Z","shell.execute_reply.started":"2022-08-07T21:17:48.482926Z","shell.execute_reply":"2022-08-07T21:17:48.510906Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Finally, we will replace nulls. For any categorical variable, we will use the mode to ","metadata":{}},{"cell_type":"code","source":"clean_ckd['age'].fillna(clean_ckd['age'].mean(),inplace =True)\nclean_ckd['bp'].fillna(clean_ckd['bp'].mean(),inplace =True)\nclean_ckd['sg'].fillna(clean_ckd['sg'].mean(),inplace =True)\nclean_ckd['al'].fillna(clean_ckd['al'].mean(),inplace =True)\nclean_ckd['su'].fillna(clean_ckd['su'].mean(),inplace =True)\nclean_ckd['pcc'].fillna(clean_ckd['pcc'].mode()[0],inplace =True)\nclean_ckd['ba'].fillna(clean_ckd['ba'].mode()[0],inplace =True)\nclean_ckd['bgr'].fillna(clean_ckd['bgr'].mean(),inplace =True)\nclean_ckd['bu'].fillna(clean_ckd['bu'].mean(),inplace =True)\nclean_ckd['sc'].fillna(clean_ckd['sc'].mean(),inplace =True)\nclean_ckd['hemo'].fillna(clean_ckd['ba'].mean(),inplace =True)\nclean_ckd['htn'].fillna(clean_ckd['htn'].mode()[0],inplace =True)\nclean_ckd['dm'].fillna(clean_ckd['dm'].mode()[0],inplace =True)\nclean_ckd['cad'].fillna(clean_ckd['cad'].mode()[0],inplace =True)\nclean_ckd['appet'].fillna(clean_ckd['appet'].mode()[0],inplace =True)\nclean_ckd['pe'].fillna(clean_ckd['pe'].mode()[0],inplace =True)\nclean_ckd['ane'].fillna(clean_ckd['ane'].mode()[0],inplace =True)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:48.514173Z","iopub.execute_input":"2022-08-07T21:17:48.515029Z","iopub.status.idle":"2022-08-07T21:17:48.539658Z","shell.execute_reply.started":"2022-08-07T21:17:48.514985Z","shell.execute_reply":"2022-08-07T21:17:48.538535Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"clean_ckd.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:48.540984Z","iopub.execute_input":"2022-08-07T21:17:48.541514Z","iopub.status.idle":"2022-08-07T21:17:48.565112Z","shell.execute_reply.started":"2022-08-07T21:17:48.541468Z","shell.execute_reply":"2022-08-07T21:17:48.563307Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"#### There are no longer any nulls in the data set! The data is ready to move to the Exploratory Data Analysis Phase.","metadata":{}},{"cell_type":"markdown","source":"### Discussion of Data Cleaning Results: \nIn this section, the data set was closely examined, cleaned, and prepped for future model training.\n* **Extraneous Features:** \"ID\" was removed since it did not offer any additional information about the patient and was meant as a numerical patient identifier number not a variable in the data set. \n* **Imbalance:** As was evident above, this data set was imbalanced, with 150 instances of NOT CKD and 250 instances of CKD. This issue will be addressed in the model build section by oversampling the minority class of the training data set. This is a strategy used in machine learning to address imbalanced (and small size data sets)\n* **Missing Features:** The data set had a number of missing values and was not suitable for complete case analysis. Each feature with nulls was considered for imputation or removal based on a 15% null value threshold. As a result, seven features were removed and 17 features were imputed (although some had < 1% of nulls). The features were imputated using the mean value if the feature was numerical and mode if the feature was categorical. Imputation was the ideal choice over complete removal over each feature containing nulls, as it is important to maintain as many features as possible to understand the impact each feature has on the target variable. If we removed all features with nulls, there is the risk of having removed features that are contributors to the final classification decision. To account for the imputations, the models will be evaluated with K-Fold Cross Validation.\n* **Encoding:** There were several categorical features that were encoded to 0/1 since machine learning models need numerical values instead of categorical ones.\n\nUltimately, a combination of tables and plots were used as the visualizations to thoroughly examine the data set. In addition to removing missing features, this section also changed the features values to a binary category (in place of words) further polishing the data set and prepping for the next steps.","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)\nNow that the data has been cleaned, the next step is to examine any correlation, collinearity, and other feature traits that could impact the results of our model.","metadata":{}},{"cell_type":"markdown","source":"#### Overview: In this section, the data set will be explored via EDA. This requires several tasks:\n1. Checking for Correlation\n2. Checking for Collinearity (additional statistical test)\n3. Box Plots: Outliers and Data Distribution\n4. Histograms: Skewness\n5. Discussion of Findings","metadata":{}},{"cell_type":"markdown","source":"## 1. Checking for Correlation ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 15))\nsns.heatmap(clean_ckd.corr(), annot = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:48.566731Z","iopub.execute_input":"2022-08-07T21:17:48.567201Z","iopub.status.idle":"2022-08-07T21:17:50.412333Z","shell.execute_reply.started":"2022-08-07T21:17:48.567031Z","shell.execute_reply":"2022-08-07T21:17:50.410758Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"The heatmap of the correlation matrix displays the relationship between features in the model. The values in a heatmap range from -1 to 1 with 0 indicating that the two variables in question do not have a strong linear relationship. As is evident in the diagonal row, each feature is strongly correlated to itself. \n\nIt is important to examine this plot for any correlation between two features in the model. A negative number indicates a negative correlation between the variables (for example,the relationship between Specific Gravity (sg) and Albumin (al) at -0.47). \n\nA positive number indicates a positive correlation between two variables (for example, the relationship between Sugar (su) and Blood Glucose Random (bgr) at 0.64). This means that as the value for sugar increases the value for blood glucose random will also increase. These two features both measure sugar, one in urine and one in a blood sample. Despite both being measures of sugar, the correlation is still only 0.64, so neither feature will be removed to prevent information loss. We will re-evaluate this decision in the model section where feature importance will be quantified and some features will be dropped).\n\nThe feature will the lowest correlation to Classification (the target variable) is Bacteria (Ba) with a value of 0.19.","metadata":{}},{"cell_type":"markdown","source":"## 2. Checking for Collinearity","metadata":{}},{"cell_type":"code","source":"X = add_constant(clean_ckd) # need a constant in order to perform the VIF (acts as the baseline)\nX.drop('classification', axis = 1, inplace = True) # drop the target variable to only examine the collinearity between features \nVIF = pd.DataFrame() #create a dataframe to contain the information\nVIF[\"feature\"] = X.columns #set columns of VIF to be the features\nVIF[\"VIF\"] = [variance_inflation_factor(X.values, i) \n               for i in range(X.shape[1])] # calc the VIF for each feature \nprint(VIF)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:50.413843Z","iopub.execute_input":"2022-08-07T21:17:50.414347Z","iopub.status.idle":"2022-08-07T21:17:50.480405Z","shell.execute_reply.started":"2022-08-07T21:17:50.414272Z","shell.execute_reply":"2022-08-07T21:17:50.479098Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"The Variable Influence Factor (VIF) indicates the collinearity of one feature with another. A lower value (~1) indicates that there is no collinearity (or minimal collinearity) for that feature. A value greater than one and less than five indicates mild collinearity and a value greater than five indicates strong collinearity  (source: https://www.geeksforgeeks.org/detecting-multicollinearity-with-vif-python/). As is evident from the table above, no feature exhibits strong collinearity and all values are about 2 or less. Therefore, no features will be removed.","metadata":{}},{"cell_type":"markdown","source":"## 3. Box Plots: Outliers and Data Distribution","metadata":{}},{"cell_type":"markdown","source":"Now we will look at some boxplots of interest. I have chosen to look at a subset of the total features (i.e. those with numerical values) since these will yield more insight than the binary encoded categorical feature values.","metadata":{}},{"cell_type":"code","source":"box_plot_features = ['age', 'bp', 'bu', 'hemo', 'bgr', 'su'] #specific subset of features for the boxplots.\nfor c in box_plot_features: # plotting distribution of data for ckd vs not_ckd to understand how data distribution changes.\n    CKD = clean_ckd[clean_ckd['classification']== 1][c] #split into CKD instances\n    NOT_CKD = clean_ckd[clean_ckd['classification']== 0][c] #get the NOT CKD instances to compare the two distributions\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.boxplot([CKD, NOT_CKD], notch = True, labels = ['CKD', 'NOT_CKD'])\n    plt.ylabel(c)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:50.482688Z","iopub.execute_input":"2022-08-07T21:17:50.483622Z","iopub.status.idle":"2022-08-07T21:17:51.654950Z","shell.execute_reply.started":"2022-08-07T21:17:50.483570Z","shell.execute_reply":"2022-08-07T21:17:51.653522Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"The above box plots compare the distribution of instances of kidney disease vs not kidney disease. It is evident that the data is distributed differently between CKD and not CKD. For the CKD instances, the data distribution is more variable (evidenced by the larger boxes) and there are more outliers. These outliers could be indicative of a disease (i.e. CKD) and therefore should remain in the data set. ","metadata":{}},{"cell_type":"markdown","source":"## 4. Histograms: ","metadata":{}},{"cell_type":"code","source":"clean_ckd.hist(figsize = (16, 16)) #plot histogram of each feature","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:51.658937Z","iopub.execute_input":"2022-08-07T21:17:51.659977Z","iopub.status.idle":"2022-08-07T21:17:54.398159Z","shell.execute_reply.started":"2022-08-07T21:17:51.659935Z","shell.execute_reply":"2022-08-07T21:17:54.396961Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"The histograms show that the distribution of each feature is different. Age is slightly right skewed, indicating more older patients were observed than younger patients. Blood Pressure (bp) is slightly left skewed, with more patients having low bp than high bp. There are a total of 13 features that are left skewed and 4 features that are right skewed as well as one feature that is randomly distributed. The skewness in the data set could impact machine learning model performance for some models types and will need to be taken into consideration when building and evaluating the machine learning models. For this reason, it will be interesting to compare the performance of parametric vs non parametric machine learning models on the data set. Given the skewed dataset, it is expected that the non parametric model (SVM or Random Forest) would outperform a parametric model (logistic regression) since the latter makes assumptions about the fit function and therefore expects a certain format while the non parametric do not make assumptions about the data (James et. al., 22).","metadata":{}},{"cell_type":"markdown","source":"## 5. Discussion of Exploratory Data Analysis Findings: \nIn this section, the data set closely explored and any data set traits were considered before progressing to building the machine learning models.\n* **Correlation:** The correlation matrix visually demonstrates the relationship between features and between features and the target variable. As was discussed above, some features are correlated, however, no features were completely correlated (1 or -1). The feature importance will be addressed in the next section and the results of the correlation matrix will be revisited. Overall, the results of the correlation matrix show there is some correlation between features, which is to be expected since the features are all medical measures of bodily function and some are measures of the same type but at different steps in the bodily process (for example sugar is measured from a urine sample while blood glucose random is a measure of sugar in the blood.  \n* **Collinearity:** An extra statistical test called the Variable Influence Factor (VIF) was conducted to further explore the data set. This statistical test is a measure of collinearity and values above a \"5\" are considered to have strong collinearity. Since none of the features in the data set had a value above the threshold, no features will be removed from the dataset as a result of collinearity.\n* **Outliers and Data Distribution:** The above boxplots explored the distribution of several numerical features to further explore the data set. Furthermore, the data set was divided into instances of CKD and instances of NOT CKD to compare the distributions and outliers in the data set. Upon inspection, there were outliers present in the CKD group, however, since these outliers could be strong indicators of abnormal body function (i.e. a serious disease or illness) they will not be removed.\n* **Histograms** The histograms for the features showed that some of the data set features are skewed. This is a good opportunity to compare parametric vs non parametric binary classification machine learning models. It is expected that a non parametric model would outperform a parametric model since the former does not make assumptions about the fit function while the latter expects a certain function format (James et. al., 22). \n\nA combination of visualizations (tables, plots, heatmaps) was used to further explore the data set. Now that the data set has been completely examined and cleaned, we can move on to the model build.","metadata":{}},{"cell_type":"markdown","source":"# **Models**","metadata":{}},{"cell_type":"markdown","source":"#### Overview: In this section, the data set will be used to build several machine learning models. This section includes:\n1. Splitting the Data Set\n2. Addressing Class Imbalance\n3. Logistic Regression\n    * Baseline Case\n    * Optimization via Feature Importance\n    * Results and Analysis\n4. Decision Tree Classifier\n    * Baseline Case\n    * Optimization & K-Fold Cross Validation\n    * Results and Analysis\n5. Random Forest Classifier\n    * Baseline Case\n    * Optimization & K-Fold Cross Validation\n    * Results and Analysis\n6. Comparison of Models\n\n#### **Model Selection**:\nThe models listed above were chosen in careful consideration of the dataset and type of problem at hand. Since this is a binary class classification problem, the suitable models are Classification models. Furthermore, given the size of the data set and number of features, Logistic Regression, Decision Tree Classifier, and Random Forest Classification were all suitable choices for answering the question.\n\n#### **Feature Engineering**:\nIn the section on Data Cleaning, the features were all one hot encoded from their categorical labels to binary 0 and 1. Feature selection based on feature importance will be used to optimize the logistic regression model since there are no hyperparameters in logistic regression.\n\n#### **Collinearity**:\nIn the Exploratory Data Analysis section, VIF statistical analysis was used to address any potential collinearity/interation. As discussed above, the data set demonstrates mild collinearity and so no features will be removed before proceeding with the model. It is important to note that collinearity would have an impact on logistic regression and support vector machine while random forest is robust against collinearity due to the sampling methods used to build the model.\n\n#### **Performance Metrics**:\nSince the dataset is imbalanced, accuracy is not the best choice for evaluating model performance. The models will be evaluated and optimized using the f1 score (since this is a good metric for an imbalanced dataset). The f1 score is a single score that represents both the precision and recall of a model. The final models will be evaluated based on f1 score and confusion matrix to have a comprehensive comparison amongst models. The confusion matrix is important for a classification problem in the medical field since the number of false negatives needs to be carefully considered so as to avoid missing a possible diagnosis.\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Splitting the Data Set\nThe data set will be split into 60% train, 20% test, and 20% validation. We will use the validation data set to perform K-Fold Cross Validation to mitigate the effects of the imputations and the imbalanced data set discussed in the above section on data cleaning.","metadata":{}},{"cell_type":"code","source":"y = clean_ckd['classification'].values # y values will be the \"labels\" which in this data set are CKD (1) or NOT CKD (0).\nX = clean_ckd.drop('classification', axis = 1).values # the features and observations are the x values that want to predict the y label\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 50) # first split into test and train\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.25, random_state = 50) #then further split the test data to get validation data set\n\nprint('train:', x_train.shape,'test:', x_test.shape, 'val:', x_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:54.400298Z","iopub.execute_input":"2022-08-07T21:17:54.401133Z","iopub.status.idle":"2022-08-07T21:17:54.412471Z","shell.execute_reply.started":"2022-08-07T21:17:54.401086Z","shell.execute_reply":"2022-08-07T21:17:54.411713Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## 2. Addressing Class Imbalance\n\nAs was evident in the EDA, there is a class imbalance in this data set. In order to appropriately handle the imbalance, the **training** data set's minority class will be oversampled. Oversampled means that the minority class, in this case NOT CKD, will duplicate instances of observations in order to have the same class number as the majority data class. The oversampling occurs on the training data set only so that the test data set remains unaffected.","metadata":{}},{"cell_type":"code","source":"ros = RandomOverSampler(random_state=12)\nx_train, y_train = ros.fit_resample(x_train, y_train) #oversampling of the minority class so that it is the same size as the majority class","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:54.413900Z","iopub.execute_input":"2022-08-07T21:17:54.414445Z","iopub.status.idle":"2022-08-07T21:17:54.429831Z","shell.execute_reply.started":"2022-08-07T21:17:54.414413Z","shell.execute_reply":"2022-08-07T21:17:54.428874Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## 3. Logistic Regression\n* ### Baseline Case: \nThe following model is built with no optimization and will be used to compare to the model after optimization and K fold cross validation has been completed.","metadata":{}},{"cell_type":"code","source":"# Baseline Case for Logistic Regression\nlog_reg = LogisticRegression(solver = 'liblinear', class_weight = 'balanced').fit(x_train, y_train) #choose balanced as the class weight since the data set is imbalanced\ny_pred = log_reg.predict(x_train) \nyhat = log_reg.predict(x_test)\nprint(classification_report(y_test, yhat)) #generate a report for all metrics\nlog_reg_f1 = f1_score(y_test, yhat) #save the f1 score for later model comparison/evaluation\nprint('f1:', log_reg_f1)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:54.431635Z","iopub.execute_input":"2022-08-07T21:17:54.432823Z","iopub.status.idle":"2022-08-07T21:17:54.452425Z","shell.execute_reply.started":"2022-08-07T21:17:54.432775Z","shell.execute_reply":"2022-08-07T21:17:54.451264Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"The f1 metric for the test data set is 0.947. This is already a strong score, but we can try to improve it further by considering feature importance and cross validation.\n* ### Optimization (Feature Engineering):\nAs discussed in lecture, there is no hyperparameter for a logistic regression model. However, optimization can occur through feature importance and feature selection (a part of feature engineering). This section will use the coefficients generated above to evaluate each feature's importance in the model. This will inform if any features can be removed from the model to improve performance. ","metadata":{}},{"cell_type":"code","source":"feature_importance = log_reg.coef_[0] #from the logistic regression model we can get the coefficients for each feature\nfeatures = clean_ckd.drop('classification', axis = 1) #remove the target feature from consideration\nplt.figure(figsize = (8,8))\nplt.bar([c for c in features.columns], feature_importance) #bar plot to visually display feature importance\nplt.xlabel('Feature')\nplt.ylabel('Score')\nplt.title('Feature Importance')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:54.454141Z","iopub.execute_input":"2022-08-07T21:17:54.454772Z","iopub.status.idle":"2022-08-07T21:17:54.728280Z","shell.execute_reply.started":"2022-08-07T21:17:54.454728Z","shell.execute_reply":"2022-08-07T21:17:54.726996Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"The plot above demonstrates that there are several features that do not have a strong influence on the target feature. We will remove the three lowest contributing features and evaluate model performance. The features removed are: age, blood pressure (bp), and blood glucose random (bgr). If you recall the correlation matrix heatmap from the EDA section, it was evident that there was correlation between sugar (su) and blood glucose random (bgr). Now that it has been confirmed that this feature has little impact on target feature prediction, we can remove bgr. ","metadata":{}},{"cell_type":"code","source":"x_train_drop= np.delete(x_train, [0, 1, 7], axis = 1) #remove the three features discussed above from the training set\nx_test_drop= np.delete(x_test,[0,1,7], axis= 1) #remove the three features discussed above from the test set.","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:54.737300Z","iopub.execute_input":"2022-08-07T21:17:54.737771Z","iopub.status.idle":"2022-08-07T21:17:54.744259Z","shell.execute_reply.started":"2022-08-07T21:17:54.737738Z","shell.execute_reply":"2022-08-07T21:17:54.742867Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"Now that the features with the lowest coefficients have been removed, a new logistic regression model will be fit using the training data set. It will also be evaluated for any improvement in f1 (recall) performance.","metadata":{}},{"cell_type":"code","source":"log_reg_new = LogisticRegression(solver = 'liblinear', class_weight = 'balanced').fit(x_train_drop, y_train) #fit a model with the updated x_train data set\ny_pred_drop = log_reg_new.predict(x_train_drop)\nyhat_drop = log_reg_new.predict(x_test_drop)\nprint(classification_report(y_test, yhat_drop)) #print all metrics \nlog_reg_f1_drop = f1_score(y_test, yhat_drop) #store the f1 variable for future comparison\nprint('f1_features:', log_reg_f1_drop)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:54.746026Z","iopub.execute_input":"2022-08-07T21:17:54.746465Z","iopub.status.idle":"2022-08-07T21:17:54.766368Z","shell.execute_reply.started":"2022-08-07T21:17:54.746409Z","shell.execute_reply":"2022-08-07T21:17:54.764503Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"By dropping the features, there f1 score improves from 94.7% to 95.6%. Now, we will confirm feature importance and iterate again by dropping additional features if necessary.","metadata":{}},{"cell_type":"code","source":"feature_importance_2 = log_reg_new.coef_[0] #from the logistic regression model we can get the coefficients for each feature\nfeatures_2 = clean_ckd.drop('classification', axis = 1)#remove the target feature from consideration\nfeatures_2.drop('age', axis = 1, inplace = True)\nfeatures_2.drop('bp', axis = 1, inplace = True)\nfeatures_2.drop('bgr' , axis = 1, inplace = True)#remove the target feature from consideration\nplt.figure(figsize = (8,8))\nplt.bar([c for c in features_2.columns], feature_importance_2) #bar plot to visually display feature importance\nplt.xlabel('Feature')\nplt.ylabel('Score')\nplt.title('Feature Importance')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:54.768122Z","iopub.execute_input":"2022-08-07T21:17:54.768504Z","iopub.status.idle":"2022-08-07T21:17:55.087027Z","shell.execute_reply.started":"2022-08-07T21:17:54.768470Z","shell.execute_reply":"2022-08-07T21:17:55.085859Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"'Ba' and 'Bu' both have low feature importance relative to the rest of the features. Will drop these features and re-run the logistic regression model.","metadata":{}},{"cell_type":"code","source":"x_train_drop2= np.delete(x_train_drop, [4, 5], axis = 1) #remove the two features discussed above from the training set\nx_test_drop2= np.delete(x_test_drop,[4, 5], axis= 1) #remove the two features discussed above from the test set.","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:55.088971Z","iopub.execute_input":"2022-08-07T21:17:55.089778Z","iopub.status.idle":"2022-08-07T21:17:55.097539Z","shell.execute_reply.started":"2022-08-07T21:17:55.089725Z","shell.execute_reply":"2022-08-07T21:17:55.096453Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"log_reg_3 = LogisticRegression(solver = 'liblinear', class_weight = 'balanced').fit(x_train_drop2, y_train) #fit a model with the updated x_train data set\ny_pred_drop2 = log_reg_3.predict(x_train_drop2)\nyhat_drop2 = log_reg_3.predict(x_test_drop2)\nprint(classification_report(y_test, yhat_drop2)) #print all metrics \nlog_reg_f1_drop2 = f1_score(y_test, yhat_drop2) #store the f1 variable for future comparison\nprint('f1_features:', log_reg_f1_drop2)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:55.099358Z","iopub.execute_input":"2022-08-07T21:17:55.100113Z","iopub.status.idle":"2022-08-07T21:17:55.121868Z","shell.execute_reply.started":"2022-08-07T21:17:55.100073Z","shell.execute_reply":"2022-08-07T21:17:55.120516Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Removing the additional features did not improve the model's performance. Next, we will use this feature set to perform 5 fold cross validation to confirm.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\nlog_reg_cv = LogisticRegressionCV(cv=5, random_state=0, solver = 'liblinear', class_weight = 'balanced').fit(x_train, y_train)\npredict_cv = log_reg_cv.predict(x_test)\nprint(classification_report(y_test, predict_cv))\nlog_reg_f1_cv = f1_score(y_test, predict_cv)\nprint('f1_cv:', log_reg_f1_cv)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:55.123441Z","iopub.execute_input":"2022-08-07T21:17:55.124651Z","iopub.status.idle":"2022-08-07T21:17:55.257092Z","shell.execute_reply.started":"2022-08-07T21:17:55.124610Z","shell.execute_reply":"2022-08-07T21:17:55.255742Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Cross validation f1 score is 99.1%. This is an increase from the baseline model with 94.7%","metadata":{}},{"cell_type":"markdown","source":"* ### Analysis of Results: Logistic Regression\nFirst, let's examine the confusion matrix for the cross validated model on the test data set.","metadata":{}},{"cell_type":"code","source":"confusion_matrix_log_reg = confusion_matrix(y_test, predict_cv)\ncm_plot_log_reg = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_log_reg)\ncm_plot_log_reg.plot(cmap = 'terrain', colorbar =False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:17:55.259051Z","iopub.execute_input":"2022-08-07T21:17:55.259663Z","iopub.status.idle":"2022-08-07T21:17:55.367093Z","shell.execute_reply.started":"2022-08-07T21:17:55.259612Z","shell.execute_reply":"2022-08-07T21:17:55.365692Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrix (of the model with feature engineering) shows that there are no false positives (instances where the individual does not have CKD but is labelled as having CKD). However, there is 1 instance of false negatives (where the individual is told they do **not** have CKD but they do have CKD). For the purposes of the model we want the minimize any false negatives since diagnosis of CKD is the focus of this model.","metadata":{}},{"cell_type":"code","source":"ml_model1 = ['Baseline','Feature Drop 1','Optimized']\nf1_scores1 = [log_reg_f1, log_reg_f1_drop, log_reg_f1_cv]\nc = ['skyblue', 'navy','deepskyblue']\nfig, ax = plt.subplots(figsize=(6, 5))\nbar_plot = ax.bar(ml_model1, f1_scores1, color = c) #plot each f1 score a specific color\nax.bar_label(bar_plot) #show the f1 score on the plot\nplt.title('Logistic Regression: F1 Score Comparison')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T22:05:21.674010Z","iopub.execute_input":"2022-08-07T22:05:21.674535Z","iopub.status.idle":"2022-08-07T22:05:21.866138Z","shell.execute_reply.started":"2022-08-07T22:05:21.674496Z","shell.execute_reply":"2022-08-07T22:05:21.864706Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":"The above plot demonstrates the performance improvement as the feature selection iteration is completed. The final optimized model demonstrates an improvement in performance over each previous model.","metadata":{}},{"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(y_test, predict_cv)\nauc_log_reg = roc_auc_score(y_test, predict_cv)\nplt.plot(fpr, tpr, label = 'AUC='+str(auc_log_reg))\nplt.legend()\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')","metadata":{"execution":{"iopub.status.busy":"2022-08-07T22:00:36.687540Z","iopub.execute_input":"2022-08-07T22:00:36.688025Z","iopub.status.idle":"2022-08-07T22:00:36.900555Z","shell.execute_reply.started":"2022-08-07T22:00:36.687980Z","shell.execute_reply":"2022-08-07T22:00:36.899285Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"The shape of the ROC (Receiver Operator Curve) is ideal. Furthermore, the AUC performance exceeds that of 0.5, which is the point at which the model would be equivalent to making random classifications (since this is a binary classification problem the odds of predicting correctly at random is 0.5).","metadata":{}},{"cell_type":"markdown","source":"In this section, a baseline logistic model was built and fit to evaluate classification performance for predicting instances of chronic kidney disease (CKD). The baseline model showed strong performance in its f1 score (at 94.7%). The model performance was improved in two ways, first by evaluating feature performance and then by running 5-Fold Cross validation with the updated data set (features with little contribution were removed). The model f1 score improved from 94.7% to 99.1%. Ultimately, this is a strong model that performs well, however, it does label 1 instances in the testing data set with false negatives From a medical standpoint, this is not good, since false negatives allow patients to remain undiagnosed and potentially risk dangerous health consequences. This logisitic regression model has demonstrated the value in using feature engineering and iteration to optimize model performance.","metadata":{}},{"cell_type":"markdown","source":"## 4. Decision Tree Classifier\n* ### Baseline Case: \nThe following model is built with no optimization and will be used to compare to the model after optimization and K fold cross validation has been completed.","metadata":{}},{"cell_type":"code","source":"dtc = DecisionTreeClassifier().fit(x_train,y_train) #baseline DTC classifier\ndtc_ytest = dtc.predict(x_test)\nprint(classification_report(y_test, dtc_ytest))\ndtc_f1 = f1_score(y_test, dtc_ytest)\nprint('f1:', dtc_f1)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:23:57.853621Z","iopub.execute_input":"2022-08-07T21:23:57.854158Z","iopub.status.idle":"2022-08-07T21:23:57.871580Z","shell.execute_reply.started":"2022-08-07T21:23:57.854120Z","shell.execute_reply":"2022-08-07T21:23:57.870365Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"The base case of the Decision Tree Classifier model has a F1 score on the test data of 99.1%. This baseline case of the decision tree classifier outperforms the logistic regression model discussed above, but additional hyperparameter optimization can be used to further improve performance. The F1 Score is used since this is an imbalanced data set.\n\n### Optimization and Cross Validation:\n\n* Now, we will use Cross Validation and optimization of several hyperparameters to improve model performance. The different loss criterion for deciding tree split and the maximum number of features considered will be explored.","metadata":{}},{"cell_type":"code","source":"params_dtc = param_grid = {  \n    'criterion' :['gini', 'entropy'], \n    'max_features' : ['auto', 'sqrt', 'log2']} #dictionary for all parameters that will form the tradespace.\ndtc_cv = DecisionTreeClassifier()\ndtc_grid = GridSearchCV(dtc_cv,params_dtc,cv=5, scoring = 'f1') # setting up a grid search \ndtc_grid.fit(x_val, y_val) #fitting each grid search product with the validation dataset\nprint(\"Best F1 score: \", dtc_grid.best_score_)\nprint(\"Best hyperparameters: \", dtc_grid.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:26:06.095840Z","iopub.execute_input":"2022-08-07T21:26:06.096252Z","iopub.status.idle":"2022-08-07T21:26:06.167985Z","shell.execute_reply.started":"2022-08-07T21:26:06.096219Z","shell.execute_reply":"2022-08-07T21:26:06.167168Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"opt_dtc= DecisionTreeClassifier(criterion = 'entropy', max_features=  'auto') #use the features identified as the best hyperparameters for the optimized model\nopt_dtc.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:26:26.152058Z","iopub.execute_input":"2022-08-07T21:26:26.152443Z","iopub.status.idle":"2022-08-07T21:26:26.161606Z","shell.execute_reply.started":"2022-08-07T21:26:26.152412Z","shell.execute_reply":"2022-08-07T21:26:26.160420Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"dtc_u_ypred = opt_dtc.predict(x_train) #predict with the optimized model\ndtc_u_yhat = opt_dtc.predict(x_test)\nprint(classification_report(y_test, dtc_u_yhat))\ndtc_u_f1 = f1_score(y_test, dtc_u_yhat) #get f1 score for the optimized model\nprint('F1 score:', dtc_u_f1)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:26:28.187433Z","iopub.execute_input":"2022-08-07T21:26:28.187840Z","iopub.status.idle":"2022-08-07T21:26:28.206381Z","shell.execute_reply.started":"2022-08-07T21:26:28.187808Z","shell.execute_reply":"2022-08-07T21:26:28.205365Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"* ### Analysis of Results: Decision Tree Classifier\nIn this section, a baseline decision tree model was built and fit to evaluate classification performance for predicting instances of chronic kidney disease (CKD). The baseline model showed strong performance in its f1 score (at 99.1%). The model performance was improved using hyperparameter optimization. The model f1 score improved from 99.1% to 100%. Ultimately, this is a strong model that performs well, and the final optimized model does not produce any false negatives in the test data set. ","metadata":{}},{"cell_type":"code","source":"confusion_matrix_dtc = confusion_matrix(y_test, dtc_u_yhat)\ncm_plot_dtc = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_dtc)\ncm_plot_dtc.plot(cmap = 'terrain', colorbar =False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:26:57.254902Z","iopub.execute_input":"2022-08-07T21:26:57.255388Z","iopub.status.idle":"2022-08-07T21:26:57.381396Z","shell.execute_reply.started":"2022-08-07T21:26:57.255352Z","shell.execute_reply":"2022-08-07T21:26:57.379769Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"As is evident, this model correctly classifies each instance in the test data set and has no false negatives or false positives. This is desirable, especially for a model used for medical purposes.","metadata":{}},{"cell_type":"code","source":"ml_models = ['Baseline','Optimized']\nf1_scores = [dtc_f1, dtc_u_f1]\nc = ['plum', 'darkorchid']\nplt.bar(ml_models, f1_scores, color = c)\nplt.title('Decision Tree Classifier: F1 Score Comparison')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:29:05.878514Z","iopub.execute_input":"2022-08-07T21:29:05.879049Z","iopub.status.idle":"2022-08-07T21:29:06.009528Z","shell.execute_reply.started":"2022-08-07T21:29:05.879009Z","shell.execute_reply":"2022-08-07T21:29:06.007166Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"fpr_dtc, tpr_dtc, thresholds_dtc = roc_curve(y_test, dtc_u_yhat) #get fpr and tpr for plotting the ROC curve\nauc_dtc = roc_auc_score(y_test, dtc_u_yhat)\nplt.plot(fpr_dtc, tpr_dtc, label = 'AUC='+str(auc_dtc))\nplt.legend()\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')","metadata":{"execution":{"iopub.status.busy":"2022-08-07T22:09:41.065979Z","iopub.execute_input":"2022-08-07T22:09:41.066486Z","iopub.status.idle":"2022-08-07T22:09:41.282371Z","shell.execute_reply.started":"2022-08-07T22:09:41.066449Z","shell.execute_reply":"2022-08-07T22:09:41.280748Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"In this section, a baseline Decision Tree Classifier model was built and fit to evaluate classification performance for predicting instances of chronic kidney disease (CKD). The baseline model showed strong performance in its f1 score (at 99.1%) which already exceeded the optimized logistic regression model. The model performance was improved by 5-Fold Cross validation and hyperparameter optimization. The model f1 score improved from 99.1% to 100%. Ultimately, this is a strong model that performs well and, after optimization, doesn't produce any false negatives in the test dataset.","metadata":{}},{"cell_type":"markdown","source":"## 5. Random Forest Classifier\n* ### Baseline Case: \nThe following model is built with no optimization and will be used to compare to the model after optimization and K fold cross validation has been completed.","metadata":{}},{"cell_type":"code","source":"rfc = RandomForestClassifier().fit(x_train, y_train) #build a baseline rfc model and fit with training data\nrfc_ytrain = rfc.predict(x_train) #predict on training\nrfc_ytest = rfc.predict(x_test) #predict on test set\nprint(classification_report(y_test, rfc_ytest)) \nrfc_f1 = f1_score(y_test, rfc_ytest)\nprint('f1:', rfc_f1)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:31:38.688263Z","iopub.execute_input":"2022-08-07T21:31:38.688662Z","iopub.status.idle":"2022-08-07T21:31:38.878641Z","shell.execute_reply.started":"2022-08-07T21:31:38.688631Z","shell.execute_reply":"2022-08-07T21:31:38.877404Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"The base case of the Random Forest Classifier model has a F1 score on the test data of 100%. This already outperforms the logistic regression model discussed above, and is the best \"out of the box\" performer that was considered for this project. This makes sense because this is a non parametric model, which handles skewed data better than a parametric model and it is also an ensemble method, meaning that it takes multiple individual models and leverages them together to optimize the model's performance.\n\n* ###  Optimization and Cross Validation:\n\nSince the model already meets 100% for its f1 score (and all other metrics), the model does not need further optimization.","metadata":{}},{"cell_type":"markdown","source":"* ### Analysis of Results: Random Forest Classifier\nFirst, let's examine the confusion matrix for the final model. ","metadata":{}},{"cell_type":"code","source":"confusion_matrix_rfc = confusion_matrix(y_test, rfc_ytest)\ncm_plot_rfc = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_rfc)\ncm_plot_rfc.plot(cmap = 'terrain', colorbar =False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:38:27.641641Z","iopub.execute_input":"2022-08-07T21:38:27.642143Z","iopub.status.idle":"2022-08-07T21:38:27.769101Z","shell.execute_reply.started":"2022-08-07T21:38:27.642107Z","shell.execute_reply":"2022-08-07T21:38:27.767069Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"As is evident, this model correctly classifies each instance in the test data set and has no false negatives or false positives. This is desirable, especially for a model used for medical purposes.","metadata":{}},{"cell_type":"code","source":"fpr_rfc, tpr_rfc, thresholds_rfc = roc_curve(y_test, rfc_ytest)\nauc_rfc = roc_auc_score(y_test, rfc_ytest)\nplt.plot(fpr_rfc, tpr_rfc, label = 'AUC='+str(auc_rfc))\nplt.legend()\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')","metadata":{"execution":{"iopub.status.busy":"2022-08-07T22:13:31.025629Z","iopub.execute_input":"2022-08-07T22:13:31.027027Z","iopub.status.idle":"2022-08-07T22:13:31.239597Z","shell.execute_reply.started":"2022-08-07T22:13:31.026970Z","shell.execute_reply":"2022-08-07T22:13:31.238437Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"ml_models = ['Baseline']\nf1_scores = [rfc_f1]\nc = ['lightgreen']\nplt.bar(ml_models, f1_scores, color = c)\nplt.title('Random Forest Classifier: F1 Score Comparison')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:39:09.173975Z","iopub.execute_input":"2022-08-07T21:39:09.174517Z","iopub.status.idle":"2022-08-07T21:39:09.353196Z","shell.execute_reply.started":"2022-08-07T21:39:09.174469Z","shell.execute_reply":"2022-08-07T21:39:09.351729Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"In this section, a baseline random forest classifier (RFC) was built and fit to evaluate classification performance for predicting instances of chronic kidney disease (CKD). The baseline model had a 100% f1 score and accuracy score. The model did not undergo any additional hyperparameter optimization since this was not necessary. This model is an non parametric ensemble method, meaning that it is robust against any skew (seen in the histograms in the EDA section) and collinearity (in this data set there is only mild collinearity), which is possibly a factor in why the model did not need hyperparameter optimization. \n\nUltimately, this is a strong model that performs well, and does not yield any false positives or false negatives in the test dataset. From a medical standpoint, this is good, since false negatives allow patients to remain undiagnosed and potentially risk dangerous health consequences.","metadata":{}},{"cell_type":"markdown","source":"## 6. Model Comparison\nIn this section, the models presented above will be compared and evaluated. The f1 scores for the baseline and optimized models will be presented and each correlation matrix will be displayed side by side to allow for close comparison. The f1 score was chosen since the data set is imbalanced and the confusion matrix is of interest since this is a medical diagnosis problem and we want the model to minimize the number of False Negatives.","metadata":{}},{"cell_type":"code","source":"ml_models = ['Log Reg','Log Reg Opt.' ,'DTC', 'DTC Opt.','RFC']\nf1_scores = [log_reg_f1, log_reg_f1_cv, dtc_f1, dtc_u_f1, rfc_f1] #compile the f1 score for each model\nc = ['skyblue', 'deepskyblue', 'plum', 'darkorchid','lightgreen']\nfig, ax = plt.subplots(figsize=(12,7))\nbar_plot = ax.bar(ml_models, f1_scores, color = c) #plot each f1 score a specific color\nax.bar_label(bar_plot) #show the f1 score on the plot\nplt.title('F1 Scores of Each ML Model (Baseline & Optimized)')\nplt.ylabel('F1 Score')\nplt.xlabel('Machine Learning Model')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:43:42.956705Z","iopub.execute_input":"2022-08-07T21:43:42.957103Z","iopub.status.idle":"2022-08-07T21:43:43.193162Z","shell.execute_reply.started":"2022-08-07T21:43:42.957072Z","shell.execute_reply":"2022-08-07T21:43:43.191543Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"The above plot shows a side-by-side comparison of each model both before and after optimization (if applicable). Based on the f1 score, the Random Forest Classifier (RFC) performs the best compared to all of the other ML models. Even without optimization, the RFC has the highest f1 score (100%). The RFC is a non parametric ensemble method, meaning it is less sensitive to even the mild collinearity and skew that is seen in our data set. This is a possible cause for it's high f1 score compared to the other models that were considered. The Decision Tree Classifier is a non parametric model, which is why the model outperforms the logistic regression, given that skewed data has greater influence on parametric models (where a certain form for the fit function is expected) than non parametric models (James et. al., 22).","metadata":{}},{"cell_type":"code","source":"# Plotting the confusion matrix side by side for each of the models discussed above\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,8))\ncm_plot_log_reg.plot(cmap = 'terrain', colorbar =False, ax =ax1)\nax1.title.set_text('Logistic Regression')\n\n\ncm_plot_dtc.plot(cmap = 'terrain', colorbar =False, ax = ax2)\nax2.title.set_text('Decision Tree Classifier')\n\ncm_plot_rfc.plot(cmap = 'terrain', colorbar =False, ax=ax3)\nax3.title.set_text('Random Forest Classifier')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T21:47:39.065562Z","iopub.execute_input":"2022-08-07T21:47:39.066039Z","iopub.status.idle":"2022-08-07T21:47:39.409397Z","shell.execute_reply.started":"2022-08-07T21:47:39.066003Z","shell.execute_reply":"2022-08-07T21:47:39.407778Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrices above show that the RFC (baseline) and the optimized Decision Tree Classifier (DTC) have the fewest instances of false negatives in the model. This is important for a medical application since it is not desirable to leave a patient undiagnosed if they do in fact have CKD. However, even the model with the worst performance still has only 1 false negative in the test data set.","metadata":{}},{"cell_type":"markdown","source":"Overall, the Random Forest Classifier (RFC) offers the best classification performance for the Chronic Kidney Disease prediction application and does not require additonal hyperparameter optimization. This model offers a viable solution to classifiying instances of Chronic Kidney Disease with a high f1 score (both precision and recall) as well as a zero false negative rate.","metadata":{}},{"cell_type":"markdown","source":"# **Discussion**\n1. Lessons Learned\n2. What didn't work?\n3. Next Steps & Areas for Improvement\n4. Final Thoughts","metadata":{}},{"cell_type":"markdown","source":"## 1. Lessons Learned\nThis project has given me the opportunity to explore the application of supervised machine learning techniques to real world problems. From this experience, I have several lessons learned and takeaways that I will carry forward in future ML applications and projects\n* The data cleaning process tends to take the longest out of all sections in the project cycle. However, doing it correctly is critical for model training and ultimately answering the problem correctly and with confidence. \n* Data is messy and will not be perfect. Care and detail must be given to preparing it.\n* EDA is an insightful process and the key takeaways from that section are carried forward to understanding which machine learning models should be used for the particular data set as well as why one model might outperform another.\n* It is important to consider feature importance and hyperparameter optimization for each model (if possible). Doing so will greatly improve model performance and allow the machine learning engineer to achieve their goal.","metadata":{}},{"cell_type":"markdown","source":"## 2. What didn't work?\nThe main issue I encountered in the project related to the data cleaning and EDA portion of the project. The data set has numerous nulls that either needed to be imputed or features that needed to be removed. I wanted to ensure that I wasn't costing my model in terms of features that could influence the model classification accuracy so I spent time working in this section to make sure that I was removing only what absolutely needed to be removed. Furthermore, this data set exposed me to data set challenges that we hadn't directly encountered in the course, namely a dataset with mild collinearity as well as imbalanced classes and a skewed feature set. This exposed me to deepen my understanding on which machine learning models need to be used in this case. For example, I initially planned to use a KNN and SVM, however, upon discovering more about the data set in the EDA section I decided to switch to working with a Decision Tree Classifier and a Random Forest Classifier since these were the most pertinent to my data set needs. ","metadata":{}},{"cell_type":"markdown","source":"## 3. Next Steps & Areas for Improvement\nThis project was an excellent introduction to the CKD classification problem. A main area for improvement is additional datasets related to classfying CKD. Currently, this is one of the few datasets addresssing CKD and it is important to note that the dataset itself is rather small (400 observations) and contains numerous missing values. If additional datasets were made available, this problem could be studied with more observation instances and with less need to remove/impute features and possibly lose key information on influential features. \n\nFurthmore, I would want to build an Adaboost Classifier to compare the performance of the Random Forest with the Adaboost. I believe the reason the Random Forest performed so well was due to the fact that it is an ensemble method and it would be interesting to confirm that belief with further model building.\n","metadata":{}},{"cell_type":"markdown","source":"## 4. Final Thoughts\nThis project explored the problem of classifying instances of Chronic Kidney Disease based on features collected while each patient was in the hospital. The goal of the project was to apply a Supervised Machine Learning model to a binary classification problem for distinguishing between Chronic Kidney Disease and Not Chronic Kidney Disease. In order to acheive this goal, the dataset was cleaned, EDA was completed, and three different machine learning models were built, optimized, and trained. With optimization, each of the three models achived an f1 score greater than 99%. The optimal model for this classification was identified based on its F1 score and it's False Negative value. The optimal model was the Random Forest Classifier, with an f1 score of 100% and zero instances of false negatives in the test data set. Therefore, it is evident that machine learning models can be applied to solve the problem of predicting Chronic Kidney Disease.","metadata":{}},{"cell_type":"markdown","source":"# Sources:\n1. Brownlee, J. (2021, January 4). Random oversampling and undersampling for imbalanced classification. Machine Learning Mastery. Retrieved August 6, 2022, from https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/#:~:text=Random%20oversampling%20involves%20randomly%20selecting,them%20from%20the%20training%20dataset. \n2. Centers for Disease Control and Prevention. (2022, February 28). Chronic kidney disease basics. Centers for Disease Control and Prevention. Retrieved August 6, 2022, from https://www.cdc.gov/kidneydisease/basics.html \n3. Detecting multicollinearity with VIF - python. GeeksforGeeks. (2020, August 29). Retrieved August 6, 2022, from https://www.geeksforgeeks.org/detecting-multicollinearity-with-vif-python/\n4. Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of\n    Information and Computer Science.\n5. Iqbal, M. (2017, April 13). Chronic kidney disease dataset. Kaggle. Retrieved August 6, 2022, from https://www.kaggle.com/datasets/mansoordaku/ckdisease \n6. James, G., Hastie, T. J., Tibshirani, R., Witten, D. (2021). An Introduction to Statistical Learning: With Applications in R. Springer. \n7. Nighania, K. (2019, January 30). Various ways to evaluate a machine learning models performance. Medium. Retrieved August 6, 2022, from https://towardsdatascience.com/various-ways-to-evaluate-a-machine-learning-models-performance-230449055f15 \n8. U.S. Department of Health and Human Services. (n.d.). Chronic kidney disease (CKD). National Institute of Diabetes and Digestive and Kidney Diseases. Retrieved August 6, 2022, from https://www.niddk.nih.gov/health-information/kidney-disease/chronic-kidney-disease-ckd#:~:text=Chronic%20kidney%20disease%20(CKD)%20means,family%20history%20of%20kidney%20failure.\n\n\n### Extra Python Packages (if not standard)\n1. https://pypi.org/project/missingno/ (Missing Number package for data visualization)\n2. http://scikit-learn.org/stable/about.html (Scikit learn for model building)\n","metadata":{}}]}